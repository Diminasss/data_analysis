# Классификация данных о болезнях сердца

## Цель работы
Изучение алгоритмов и методов классификации на практике.

## Вариант и задание
Вариант 4. Набор данных: `4heart2.csv`

### Данные о болезнях сердца:
1. **Возраст**: возраст пациента (лет)
2. **Анемия**: снижение количества эритроцитов или гемоглобина (логическое значение)
3. **Высокое кровяное давление**: если у пациента гипертония (логическое значение)
4. **Креатининфосфокиназа (КФК)**: уровень фермента КФК в крови (мкг/л)
5. **Диабет**: если у пациента диабет (логическое значение)
6. **Фракция выброса**: процент крови, покидающей сердце при каждом сокращении (в процентах)
7. **Тромбоциты**: тромбоциты в крови (килотромбоциты/мл)
8. **Пол**: женщина или мужчина (бинарный)
9. **Креатинин сыворотки**: уровень креатинина сыворотки в крови (мг/дл)
10. **Натрий сыворотки**: уровень натрия сыворотки в крови (мэкв/л)
11. **Курение**: если пациент курит или нет (логическое)
12. **Время**: период наблюдения (дни)
13. **Событие смерти**: если пациент умер в течение периода наблюдения (логическое значение)

## Порядок выполнения
1. Загрузить набор данных.
2. Провести предварительную обработку данных.
3. Выделить целевую переменную, которую необходимо предсказать. Не включать эту целевую переменную в модель. Построить матрицу диаграмм рассеяния, выделив значения целевой переменной разными цветами.
4. Разбить набор данных на тренировочный и тестовый датасеты с помощью `train_test_split` и выполнить стандартизацию числовых данных с помощью `StandardScaler`.
5. Для получения оценки 5: разработать предсказательную модель качественного отклика методами:
   - Метод k-ближайших соседей
   - Дерево решений
   - Логистическая регрессия
   - Случайный лес
   Для получения оценки 4: разработать предсказательную модель качественного отклика любыми двумя методами.
6. Оценить ошибку классификации для каждого метода. Подсчитать метрики: "Accuracy", "Precision", "Recall", "Balanced accuracy", "F1 score".
7. Построить матрицу неточностей с помощью `confusion_matrix` для каждого метода.
8. Построить графики ROC-кривых для каждого метода на одном графике (4 линии на одном графике) для сравнения.
9. Сделать вывод о качестве построенного классификатора по подсчитанным метрикам.

## Ход работы

### 1. Загрузка и предварительная обработка данных
- Считан датафрейм `4heart2.csv` с помощью `pd.read_csv()`.
- Проведена проверка на наличие пропусков и дубликатов (явных и неявных).
- Результаты проверки показали, что дубликаты и пропуски отсутствуют.

### 2. Выделение целевой переменной и визуализация
- Выделена целевая переменная `DEATH_EVENT`.
- Построена матрица диаграмм рассеяния, где значения целевой переменной выделены разными цветами.
- Матрица показала, что классы частично разделимы, но в некоторых случаях сильно пересекаются.

### 3. Разбиение данных и стандартизация
- Набор данных разбит на обучающие и тестовые датасеты в пропорции 3:1.
- Выполнена стандартизация числовых данных с помощью `StandardScaler`.

### 4. Разработка моделей классификации
- Реализованы методы классификации:
  - Метод k-ближайших соседей
  - Дерево решений
  - Логистическая регрессия
  - Случайный лес
- Подсчитаны метрики: Accuracy, Precision, Recall, Balanced Accuracy, F1 score.

### 5. Оценка качества моделей
- **Случайный лес**: лучшая модель по всем метрикам (Accuracy: 0.84, Precision: 0.89, Recall: 0.63, F1 score: 0.74, Balanced Accuracy: 0.79).
- **Метод k-ближайших соседей**: второе место по качеству.
- **Логистическая регрессия**: хорошая модель, но уступает по полноте.
- **Дерево решений**: стабильная модель, но уступает по метрикам точности.

### 6. Матрицы неточностей
- Построены матрицы неточностей для каждого метода.
- Случайный лес показал наименьшее количество ошибок для класса "0" и хорошую классификацию для класса "1".

### 7. ROC-кривые
- Построены графики ROC-кривых для каждого метода на одном графике.
- Случайный лес имеет наилучший показатель AUC (0.934), что указывает на высокую точность классификации.

## Выводы
- **Случайный лес**: лучшая модель по всем метрикам, рекомендуется для использования.
- **Метод k-ближайших соседей**: хорошая альтернатива, если важна простота и интерпретация.
- **Логистическая регрессия**: подходит для задач, где важна интерпретация модели.
- **Дерево решений**: менее эффективно, но может быть улучшено с помощью ансамблевых методов.

## Ссылка на Google Colab
[Google Colab Notebook](https://colab.research.google.com/drive/1GteKpDPO66EBJvItsb1LFnLEmJPjnIG?usp=sharing)
