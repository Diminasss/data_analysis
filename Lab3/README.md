# Регрессионный анализ данных

## Цель работы
Изучение алгоритмов и методов регрессии на практике.

## Порядок выполнения работы
1. Работа выполняется в [Google Colab](https://colab.research.google.com/).
2. Выполнить регрессию по вариантам (номер варианта определяется по номеру в списке группы).

### Часть 1 - Простая линейная регрессия
1. Обучить модель простой (парной) линейной регрессии, используя для обучения значения `x1` и `y`.
2. Выполнить предсказание.
3. Создать датафрейм с истинными и предсказанными значениями. Вывести его.
4. Подсчитать и вывести метрики качества регрессии (MSE, MAE, RMSE, R2).
5. Вывести значение коэффициентов `a` и `b`.
6. Выполнить визуализацию регрессии: точки (scatter plot) и линия регрессии.
7. Построить график с разницей предсказанного и истинного значения по каждой точке.
8. Построить график следующего вида:

### Часть 2 - Полиномиальная регрессия
1. Использовать `PolynomialFeatures` для реализации модели полиномиальной регрессии. Выбрать степень полинома самостоятельно.
2. Обучить модель полиномиальной регрессии.
3. Выполнить предсказание.
4. Подсчитать и вывести метрики качества регрессии (MAE, R2).
5. Выполнить визуализацию регрессии: точки и линия регрессия.
6. Повторить пункты 1-5 минимум для ещё одной степени полинома (degree).

### Часть 3 - Решение задачи регрессии различными методами
1. Загрузить набор данных `car_price.csv`.
2. Выделить целевую переменную, которую необходимо предсказать (важно не ошибиться с выбором целевой переменной). Выполнить для целевой переменной визуализацию - построить гистограмму и boxplot.
3. Построить матрицу диаграмм рассеяния.
4. Разделить данные на обучающую и валидационные выборки.
5. Нормализовать числовые данные с помощью `StandardScaler`.
6. Обучить модель линейной регрессии с помощью `LinearRegression`.
7. Применить обученную модель на тестовой выборке и оценить её качество с помощью метрик (минимум 4 метрики).
8. Создать датафрейм с истинными и предсказанными значениями. Вывести его.
9. Создать датафрейм с признаками и значением коэффициентов для каждого признака. Сделать выводы относительно важности признаков.
10. Выполнить визуализацию. Отобразить на графике фактическое и предсказанное значение.
11. Для получения оценки 5 - реализовать регрессию методом k-ближайших соседей или деревом решений.
12. Для метода, реализованного в пункте 11 подсчитать метрики, выполнить визуализацию фактического и предсказанного значения. Сравнить результаты, полученные всеми методами. Для этого может потребоваться визуализировать истинные и предсказанные значения на одном графике для разных методов.

## Исходные данные
### Набор данных: `car_price.csv`
Содержит информацию о ценах на автомобили, включая:
- Мощность в лошадиных силах.
- Объём двигателя.
- Длина машины.
- Расход по городу.
- Расход по шоссе.

## Выполненные задачи

### Часть 1 - Простая линейная регрессия
1. **Обучение модели**:
   - Модель была обучена на значениях `x1` и `y`.
   - Создан датафрейм с истинными и предсказанными значениями.
2. **Метрики качества**:
   - MSE (Mean Squared Error)
   - MAE (Mean Absolute Error)
   - RMSE (Root Mean Squared Error)
   - R2 (Coefficient of Determination)
3. **Визуализация**:
   - Построен график точек и линии регрессии.
   - Построен график разницы предсказанного и истинного значения.

### Часть 2 - Полиномиальная регрессия
1. **Обучение модели**:
   - Использованы полиномы 2 и 3 степени.
   - Подсчитаны метрики MAE и R2.
2. **Визуализация**:
   - Построены графики для полиномов 2 и 3 степени.

### Часть 3 - Решение задачи регрессии различными методами
1. **Загрузка данных**:
   - Загружен набор данных `car_price.csv`.
   - Выделена целевая переменная - цена автомобиля.
2. **Визуализация**:
   - Построены гистограмма и boxplot для цены автомобиля.
   - Построена матрица диаграмм рассеяния.
3. **Обработка данных**:
   - Данные разделены на обучающую и валидационные выборки.
   - Нормализованы числовые данные.
4. **Обучение модели**:
   - Обучена модель линейной регрессии.
   - Подсчитаны метрики качества модели.
5. **Визуализация**:
   - Построен график фактического и предсказанного значения.
6. **Метод k-ближайших соседей**:
   - Реализована регрессия методом k-ближайших соседей.
   - Подсчитаны метрики и выполнена визуализация.

## Выводы
- **Простая линейная регрессия**:
  - Модель показала низкую точность предсказаний.
  - Значения метрик MSE, RMSE и MAE высокие, R2 близко к нулю.
- **Полиномиальная регрессия**:
  - Полиномы 2 и 3 степени значительно улучшили точность предсказаний.
  - MAE и R2 показали высокую точность модели.
- **Регрессия методом k-ближайших соседей**:
  - Метод показал более высокую точность по сравнению с линейной регрессией.
  - MAE, MSE и RMSE меньше, R2 больше.

## Ссылка на Jupyter Notebook
[Jupyter Notebook](https://colab.research.google.com/drive/1vSdkaYXS9TOVOfyuKykYhvDS8RxZB6Z4?usp=sharing)
